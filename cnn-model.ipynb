{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Carregamento dos Dados",
   "id": "762c891695fa1f8e"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-05T00:34:18.182868Z",
     "start_time": "2025-07-05T00:34:17.415833Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/train\",\n",
    "    labels=\"inferred\", # Os rótulos são definidos a partir dos nomes das subpastas\n",
    "    label_mode=\"categorical\", # Formato categórico dos rótulos\n",
    "    batch_size=32, # Lotes de 32 imagens\n",
    "    image_size=(128, 128), # Redimensiona as imagens para 128x128\n",
    "    shuffle=True, # Embaralha as imagens para evitar que a rede aprenda padrões de ordenação\n",
    ")\n",
    "\n",
    "test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/test\",\n",
    "    labels=\"inferred\", # Os rótulos são definidos a partir dos nomes das subpastas\n",
    "    label_mode=\"categorical\", # Formato categórico dos rótulos\n",
    "    batch_size=32, # Lotes de 32 imagens\n",
    "    image_size=(128, 128), # Redimensiona as imagens para 128x128\n",
    "    shuffle=False, # Não precisa embaralhar nos dados de teste\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"dataset/validation\",\n",
    "    labels=\"inferred\", # Os rótulos são definidos a partir dos nomes das subpastas\n",
    "    label_mode=\"categorical\", # Formato categórico dos rótulos\n",
    "    batch_size=32, # Lotes de 32 imagens\n",
    "    image_size=(128, 128), # Redimensiona as imagens para 128x128\n",
    "    shuffle=False, # Não precisa embaralhar nos dados de validação\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7000 files belonging to 7 classes.\n",
      "Found 1400 files belonging to 7 classes.\n",
      "Found 1400 files belonging to 7 classes.\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Normalização",
   "id": "907cfe3e98437d5b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:34:18.290625Z",
     "start_time": "2025-07-05T00:34:18.191372Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Camada que normaliza as imagens do intervalo [0, 255] para [0, 1]\n",
    "normalization_layer = tf.keras.layers.Rescaling(1./255)\n",
    "\n",
    "# Aplicação a normalização às imagens de cada dataset\n",
    "train_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "val_ds = val_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "test_ds = test_ds.map(lambda x, y: (normalization_layer(x), y))"
   ],
   "id": "263f315e1002d825",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Conversão para Arrays Numpy",
   "id": "c5adf763f69f8f15"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:34:18.302663Z",
     "start_time": "2025-07-05T00:34:18.298642Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Função que converte um dataset em um array numpy\n",
    "def dataset_to_numpy(ds):\n",
    "    X_list = [] # Definição do array das imagens\n",
    "    y_list = [] # Definição do array dos rótulos\n",
    "\n",
    "    # Laço que itera em cada lote do dataset\n",
    "    for x_batch, y_batch in ds.as_numpy_iterator():\n",
    "        X_list.append(x_batch) # Adiciona o lote das imagens ao array\n",
    "        y_list.append(y_batch) # Adiciona o lote dos rótulos ao array\n",
    "\n",
    "    # Junta todos os lotes em um único array\n",
    "    X = np.concatenate(X_list, axis=0)\n",
    "    y = np.concatenate(y_list, axis=0)\n",
    "    return X, y"
   ],
   "id": "5cc46eca94c2eaa7",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-05T00:34:23.385073Z",
     "start_time": "2025-07-05T00:34:18.308176Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Aplica a conversão para array nos datasets\n",
    "X_train, y_train = dataset_to_numpy(train_ds)\n",
    "X_test, y_test = dataset_to_numpy(test_ds)\n",
    "X_val, y_val = dataset_to_numpy(val_ds)"
   ],
   "id": "63baf64edb49bb68",
   "outputs": [],
   "execution_count": 6
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
